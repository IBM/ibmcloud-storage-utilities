time="2020-11-18T12:26:50Z" level=info msg="Input arguments: /px-oci-mon -A -f -k etcd:https://2c2187ee-ecbc-4138-be14-b51d6cbb6075.659dc287bad647f9b4fe17c4e4c38dcc.databases.appdomain.cloud:32216 -c pxlicencetest0002 -secret_type k8s -userpwd **********************************************:**************************************************************** -ca /etc/pwx/etcdcerts/ca.pem -r 17001 -x kubernetes"
time="2020-11-18T12:26:50Z" level=info msg="Updated arguments: /px-oci-mon -A -f -k etcd:https://2c2187ee-ecbc-4138-be14-b51d6cbb6075.659dc287bad647f9b4fe17c4e4c38dcc.databases.appdomain.cloud:32216 -c pxlicencetest0002 -secret_type k8s -userpwd **********************************************:**************************************************************** -ca /etc/pwx/etcdcerts/ca.pem -r 17001 -x kubernetes"
time="2020-11-18T12:26:50Z" level=info msg="OCI-Monitor computed version v2.6.1-g259e5e25-dirty"
time="2020-11-18T12:26:50Z" level=info msg="REAPER: Starting ..."
time="2020-11-18T12:26:50Z" level=info msg="Service handler initialized via as DBus{type:dbus,svc:portworx.service,id:0xc0002a5000}"
time="2020-11-18T12:26:50Z" level=info msg="Activating REST server"
time="2020-11-18T12:26:50Z" level=info msg="> run-host: /bin/sh -c cat /etc/crictl.yaml || cat /var/vcap/store/crictl.yaml"
time="2020-11-18T12:26:50Z" level=info msg="Locating my container handler"
time="2020-11-18T12:26:50Z" level=info msg="> Attempt to use Docker as container handler failed" error="/var/run/docker.sock not a socket-file"
time="2020-11-18T12:26:50Z" level=info msg="> Attempt to use ContainerD as container handler failed" error="stat /run/containerd/containerd.sock: no such file or directory"
time="2020-11-18T12:26:50Z" level=info msg="> Using k8s-CRI as container handler"
time="2020-11-18T12:26:50Z" level=info msg="Detected HostNetwork setting - will track portworx status via REST"
time="2020-11-18T12:26:50Z" level=info msg="Parsed Registry/Repo docker.io/portworx from own image URN docker.io/portworx/oci-monitor:2.6.1"
time="2020-11-18T12:26:50Z" level=info msg="Removed env variables: [PATH PORTWORX_API_PORT PORTWORX_API_PORT_9001_TCP PORTWORX_API_PORT_9001_TCP_ADDR PORTWORX_API_PORT_9001_TCP_PORT PORTWORX_API_PORT_9001_TCP_PROTO PORTWORX_API_PORT_9020_TCP PORTWORX_API_PORT_9020_TCP_ADDR PORTWORX_API_PORT_9020_TCP_PORT PORTWORX_API_PORT_9020_TCP_PROTO PORTWORX_API_PORT_9021_TCP PORTWORX_API_PORT_9021_TCP_ADDR PORTWORX_API_PORT_9021_TCP_PORT PORTWORX_API_PORT_9021_TCP_PROTO PORTWORX_API_SERVICE_HOST PORTWORX_API_SERVICE_PORT PORTWORX_API_SERVICE_PORT_PX_API PORTWORX_API_SERVICE_PORT_PX_REST_GATEWAY PORTWORX_API_SERVICE_PORT_PX_SDK PORTWORX_SERVICE_PORT PORTWORX_SERVICE_PORT_9001_TCP PORTWORX_SERVICE_PORT_9001_TCP_ADDR PORTWORX_SERVICE_PORT_9001_TCP_PORT PORTWORX_SERVICE_PORT_9001_TCP_PROTO PORTWORX_SERVICE_PORT_9019_TCP PORTWORX_SERVICE_PORT_9019_TCP_ADDR PORTWORX_SERVICE_PORT_9019_TCP_PORT PORTWORX_SERVICE_PORT_9019_TCP_PROTO PORTWORX_SERVICE_PORT_9020_TCP PORTWORX_SERVICE_PORT_9020_TCP_ADDR PORTWORX_SERVICE_PORT_9020_TCP_PORT PORTWORX_SERVICE_PORT_9020_TCP_PROTO PORTWORX_SERVICE_PORT_9021_TCP PORTWORX_SERVICE_PORT_9021_TCP_ADDR PORTWORX_SERVICE_PORT_9021_TCP_PORT PORTWORX_SERVICE_PORT_9021_TCP_PROTO PORTWORX_SERVICE_SERVICE_HOST PORTWORX_SERVICE_SERVICE_PORT PORTWORX_SERVICE_SERVICE_PORT_PX_API PORTWORX_SERVICE_SERVICE_PORT_PX_KVDB PORTWORX_SERVICE_SERVICE_PORT_PX_REST_GATEWAY PORTWORX_SERVICE_SERVICE_PORT_PX_SDK STORK_SERVICE_PORT STORK_SERVICE_PORT_443_TCP STORK_SERVICE_PORT_443_TCP_ADDR STORK_SERVICE_PORT_443_TCP_PORT STORK_SERVICE_PORT_443_TCP_PROTO STORK_SERVICE_PORT_8099_TCP STORK_SERVICE_PORT_8099_TCP_ADDR STORK_SERVICE_PORT_8099_TCP_PORT STORK_SERVICE_PORT_8099_TCP_PROTO STORK_SERVICE_SERVICE_HOST STORK_SERVICE_SERVICE_PORT STORK_SERVICE_SERVICE_PORT_EXTENDER STORK_SERVICE_SERVICE_PORT_WEBHOOK]"
time="2020-11-18T12:26:50Z" level=info msg="Preparing to download Portworx image..."
time="2020-11-18T12:26:50Z" level=info msg="REST: Changing install-state: ST_UNKNOWN -> ST_INSTALL"
time="2020-11-18T12:26:50Z" level=info msg="Detected imagePullSecrets px-account-dockercfg-dpnfc"
time="2020-11-18T12:26:50Z" level=info msg="Detected imagePullPolicy Always"
time="2020-11-18T12:26:50Z" level=info msg="Attempting to retrieve latest docker.io/portworx/px-enterprise:2.6.1 image (pullPolicy Always)"
time="2020-11-18T12:26:50Z" level=info msg="Retrieved kube-system/px-account-dockercfg-dpnfc secret"
time="2020-11-18T12:26:50Z" level=info msg="Using anonymous Docker credentials"
time="2020-11-18T12:26:50Z" level=info msg="Got error while checking remote image digest for docker.io/portworx/px-enterprise:2.6.1 (will pull)" error="Not implemented"
time="2020-11-18T12:26:50Z" level=info msg="Pulling image docker.io/portworx/px-enterprise:2.6.1"
time="2020-11-18T12:26:51Z" level=info msg="Got requested Portworx image docker.io/portworx/px-enterprise:2.6.1 with digest sha256:25cbc0ec9db6794f350b3bed59e4eb9458bc49aac663fc608c4f48380daf88bd"
time="2020-11-18T12:26:51Z" level=info msg="Installed image digest sha256:25cbc0ec9db6794f350b3bed59e4eb9458bc49aac663fc608c4f48380daf88bd same as remote/pulled image's (no need to reinstall)"
time="2020-11-18T12:26:51Z" level=info msg="Installing Portworx OCI service to /opt/pwx..."
time="2020-11-18T12:26:51Z" level=info msg="Prepending computed kubelet directory mount /var/data/kubelet:/var/data/kubelet:shared"
time="2020-11-18T12:26:51Z" level=info msg="Adding computed k8s-secrets-vol as volatile mount regex"
time="2020-11-18T12:26:51Z" level=info msg="RSYNC: Found volatile mount '/var/data/kubelet/pods/b7ca6578-07ae-49c6-81ec-26c146cb35a4/etc-hosts:/etc/hosts'"
time="2020-11-18T12:26:51Z" level=info msg="> run-local: /usr/bin/rsync -aL --inplace --delete /etc/hosts /opt/pwx/oci/mounts/etc/hosts"
time="2020-11-18T12:26:51Z" level=info msg="> Changed mount /var/data/kubelet/pods/b7ca6578-07ae-49c6-81ec-26c146cb35a4/etc-hosts:/etc/hosts to /opt/pwx/oci/mounts/etc/hosts:/etc/hosts"
time="2020-11-18T12:26:51Z" level=info msg="RSYNC: Found volatile mount '/var/data/kubelet/pods/b7ca6578-07ae-49c6-81ec-26c146cb35a4/volumes/kubernetes.io~secret/etcdcerts:/etc/pwx/etcdcerts:ro'"
time="2020-11-18T12:26:51Z" level=info msg="> run-local: /usr/bin/rsync -aL --inplace --delete /etc/pwx/etcdcerts/ /opt/pwx/oci/mounts/etc/pwx/etcdcerts/"
time="2020-11-18T12:26:51Z" level=info msg="> Changed mount /var/data/kubelet/pods/b7ca6578-07ae-49c6-81ec-26c146cb35a4/volumes/kubernetes.io~secret/etcdcerts:/etc/pwx/etcdcerts:ro to /opt/pwx/oci/mounts/etc/pwx/etcdcerts:/etc/pwx/etcdcerts"
time="2020-11-18T12:26:51Z" level=info msg="RSYNC: Found volatile mount '/var/data/kubelet/pods/b7ca6578-07ae-49c6-81ec-26c146cb35a4/containers/portworx/9769c58b:/tmp/px-termination-log'"
time="2020-11-18T12:26:51Z" level=info msg="> run-local: /usr/bin/rsync -aL --inplace --delete /tmp/px-termination-log /opt/pwx/oci/mounts/tmp/px-termination-log"
time="2020-11-18T12:26:51Z" level=info msg="> Changed mount /var/data/kubelet/pods/b7ca6578-07ae-49c6-81ec-26c146cb35a4/containers/portworx/9769c58b:/tmp/px-termination-log to /opt/pwx/oci/mounts/tmp/px-termination-log:/tmp/px-termination-log"
time="2020-11-18T12:26:51Z" level=info msg="RSYNC: Found volatile mount '/var/data/kubelet/pods/b7ca6578-07ae-49c6-81ec-26c146cb35a4/volumes/kubernetes.io~secret/px-account-token-x7fnk:/var/run/secrets/kubernetes.io/serviceaccount:ro'"
time="2020-11-18T12:26:51Z" level=info msg="> run-local: /usr/bin/rsync -aL --inplace --delete /var/run/secrets/kubernetes.io/serviceaccount/ /opt/pwx/oci/mounts/var/run/secrets/kubernetes.io/serviceaccount/"
time="2020-11-18T12:26:51Z" level=info msg="> Changed mount /var/data/kubelet/pods/b7ca6578-07ae-49c6-81ec-26c146cb35a4/volumes/kubernetes.io~secret/px-account-token-x7fnk:/var/run/secrets/kubernetes.io/serviceaccount:ro to /opt/pwx/oci/mounts/var/run/secrets/kubernetes.io/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount"
time="2020-11-18T12:26:51Z" level=info msg="> run-host: /opt/pwx/bin/px-runc install -A -f -k etcd:https://2c2187ee-ecbc-4138-be14-b51d6cbb6075.659dc287bad647f9b4fe17c4e4c38dcc.databases.appdomain.cloud:32216 -c pxlicencetest0002 -secret_type k8s -userpwd **********************************************:**************************************************************** -ca /etc/pwx/etcdcerts/ca.pem -r 17001 -x kubernetes -v /var/data/kubelet:/var/data/kubelet:shared -v /opt/pwx/oci/mounts/etc/hosts:/etc/hosts -v /opt/pwx/oci/mounts/etc/pwx/etcdcerts:/etc/pwx/etcdcerts -v /opt/pwx/oci/mounts/tmp/px-termination-log:/tmp/px-termination-log -v /var/cores:/var/cores -v /var/run/dbus:/var/run/dbus -v /opt/pwx/oci/mounts/var/run/secrets/kubernetes.io/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount -e ETCD_PASSWORD=**************************************************************** -e ETCD_USERNAME=ibm_cloud_19ed797f_cf97_417f_9d5d_4045d79358aa -e HOME=/root -e HOSTNAME=kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c -e KUBERNETES_PORT=tcp://172.21.0.1:443 -e KUBERNETES_PORT_443_TCP=tcp://172.21.0.1:443 -e KUBERNETES_PORT_443_TCP_ADDR=172.21.0.1 -e KUBERNETES_PORT_443_TCP_PORT=443 -e KUBERNETES_PORT_443_TCP_PROTO=tcp -e KUBERNETES_SERVICE_HOST=172.21.0.1 -e KUBERNETES_SERVICE_PORT=443 -e KUBERNETES_SERVICE_PORT_HTTPS=443 -e PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin -e PORTWORX_API_PORT=tcp://172.21.41.113:9001 -e PORTWORX_API_PORT_9001_TCP=tcp://172.21.41.113:9001 -e PORTWORX_API_PORT_9001_TCP_ADDR=172.21.41.113 -e PORTWORX_API_PORT_9001_TCP_PORT=9001 -e PORTWORX_API_PORT_9001_TCP_PROTO=tcp -e PORTWORX_API_PORT_9020_TCP=tcp://172.21.41.113:9020 -e PORTWORX_API_PORT_9020_TCP_ADDR=172.21.41.113 -e PORTWORX_API_PORT_9020_TCP_PORT=9020 -e PORTWORX_API_PORT_9020_TCP_PROTO=tcp -e PORTWORX_API_PORT_9021_TCP=tcp://172.21.41.113:9021 -e PORTWORX_API_PORT_9021_TCP_ADDR=172.21.41.113 -e PORTWORX_API_PORT_9021_TCP_PORT=9021 -e PORTWORX_API_PORT_9021_TCP_PROTO=tcp -e PORTWORX_API_SERVICE_HOST=172.21.41.113 -e PORTWORX_API_SERVICE_PORT=9001 -e PORTWORX_API_SERVICE_PORT_PX_API=9001 -e PORTWORX_API_SERVICE_PORT_PX_REST_GATEWAY=9021 -e PORTWORX_API_SERVICE_PORT_PX_SDK=9020 -e PORTWORX_SERVICE_PORT=tcp://172.21.10.3:9001 -e PORTWORX_SERVICE_PORT_9001_TCP=tcp://172.21.10.3:9001 -e PORTWORX_SERVICE_PORT_9001_TCP_ADDR=172.21.10.3 -e PORTWORX_SERVICE_PORT_9001_TCP_PORT=9001 -e PORTWORX_SERVICE_PORT_9001_TCP_PROTO=tcp -e PORTWORX_SERVICE_PORT_9019_TCP=tcp://172.21.10.3:9019 -e PORTWORX_SERVICE_PORT_9019_TCP_ADDR=172.21.10.3 -e PORTWORX_SERVICE_PORT_9019_TCP_PORT=9019 -e PORTWORX_SERVICE_PORT_9019_TCP_PROTO=tcp -e PORTWORX_SERVICE_PORT_9020_TCP=tcp://172.21.10.3:9020 -e PORTWORX_SERVICE_PORT_9020_TCP_ADDR=172.21.10.3 -e PORTWORX_SERVICE_PORT_9020_TCP_PORT=9020 -e PORTWORX_SERVICE_PORT_9020_TCP_PROTO=tcp -e PORTWORX_SERVICE_PORT_9021_TCP=tcp://172.21.10.3:9021 -e PORTWORX_SERVICE_PORT_9021_TCP_ADDR=172.21.10.3 -e PORTWORX_SERVICE_PORT_9021_TCP_PORT=9021 -e PORTWORX_SERVICE_PORT_9021_TCP_PROTO=tcp -e PORTWORX_SERVICE_SERVICE_HOST=172.21.10.3 -e PORTWORX_SERVICE_SERVICE_PORT=9001 -e PORTWORX_SERVICE_SERVICE_PORT_PX_API=9001 -e PORTWORX_SERVICE_SERVICE_PORT_PX_KVDB=9019 -e PORTWORX_SERVICE_SERVICE_PORT_PX_REST_GATEWAY=9021 -e PORTWORX_SERVICE_SERVICE_PORT_PX_SDK=9020 -e PX_POD_IP=10.243.128.22 -e PX_TEMPLATE_VERSION=v2 -e STORK_SERVICE_PORT=tcp://172.21.135.114:8099 -e STORK_SERVICE_PORT_443_TCP=tcp://172.21.135.114:443 -e STORK_SERVICE_PORT_443_TCP_ADDR=172.21.135.114 -e STORK_SERVICE_PORT_443_TCP_PORT=443 -e STORK_SERVICE_PORT_443_TCP_PROTO=tcp -e STORK_SERVICE_PORT_8099_TCP=tcp://172.21.135.114:8099 -e STORK_SERVICE_PORT_8099_TCP_ADDR=172.21.135.114 -e STORK_SERVICE_PORT_8099_TCP_PORT=8099 -e STORK_SERVICE_PORT_8099_TCP_PROTO=tcp -e STORK_SERVICE_SERVICE_HOST=172.21.135.114 -e STORK_SERVICE_SERVICE_PORT=8099 -e STORK_SERVICE_SERVICE_PORT_EXTENDER=8099 -e STORK_SERVICE_SERVICE_PORT_WEBHOOK=443 -e TERM=xterm -e container=oci -e PX_IMAGE=docker.io/portworx/px-enterprise:2.6.1 -e CONTAINER_RUNTIME=cri/cri-o -e PX_IMAGE_DIGEST=sha256:25cbc0ec9db6794f350b3bed59e4eb9458bc49aac663fc608c4f48380daf88bd -e KUBELET_DIR=/var/data/kubelet"
time="2020-11-18T06:26:51-06:00" level=info msg="Rootfs found at /opt/pwx/oci/rootfs"
time="2020-11-18T06:26:51-06:00" level=info msg="PX binaries found at /opt/pwx/bin/px-runc"
time="2020-11-18T06:26:51-06:00" level=info msg="Initializing as version 2.6.1.0-fa99d8a (OCI)"
time="2020-11-18T06:26:51-06:00" level=info msg="Enabling Sharedv4 NFS support ..."
time="2020-11-18T06:26:51-06:00" level=info msg="Setting up NFS service"
time="2020-11-18T06:26:51-06:00" level=info msg="> Initialized service controls via DBus{type:dbus,svc:nfs-server.service,id:0xc420272740}"
time="2020-11-18T06:26:51-06:00" level=info msg="Fixing docker.sock mount:"
time="2020-11-18T06:26:51-06:00" level=info msg="> Removing mount for /var/run/docker.sock:/var/run/docker.sock:[rbind rprivate]"
time="2020-11-18T06:26:51-06:00" level=info msg="> Adding mount for /run:/var/host_run:[bind rprivate]"
time="2020-11-18T06:26:51-06:00" level=info msg="> Soft-link /opt/pwx/oci/rootfs/run/docker.sock -> /var/host_run/docker.sock already exists"
time="2020-11-18T06:26:51-06:00" level=info msg="Checking mountpoints for following shared directories: [/var/data/kubelet /var/lib/osd]"
time="2020-11-18T06:26:51-06:00" level=info msg="Found following mountpoints for shared dirs: map[/var/lib/osd:{isMP=f,Opts=shared:1,Parent=/} /var/data/kubelet:{isMP=f,Opts=shared:1,Parent=/} /:{isMP=T,Opts=shared:1}]"
time="2020-11-18T06:26:51-06:00" level=info msg="SPEC UPDATED [630890de03e7965a0306fbd2e5d36149  /opt/pwx/oci/config.json]"
time="2020-11-18T06:26:51-06:00" level=info msg="> Updated arguments: add{pxlicencetest0002} rm{democluster-pw}"
time="2020-11-18T06:26:51-06:00" level=info msg="> Updated env: add{PORTWORX_API_PORT=tcp://172.21.41.113:9001 PORTWORX_API_PORT_9001_TCP=tcp://172.21.41.113:9001 PORTWORX_API_PORT_9001_TCP_ADDR=172.21.41.113 PORTWORX_API_PORT_9020_TCP=tcp://172.21.41.113:9020 PORTWORX_API_PORT_9020_TCP_ADDR=172.21.41.113 PORTWORX_API_PORT_9021_TCP=tcp://172.21.41.113:9021 PORTWORX_API_PORT_9021_TCP_ADDR=172.21.41.113 PORTWORX_API_SERVICE_HOST=172.21.41.113 PORTWORX_SERVICE_PORT=tcp://172.21.10.3:9001 PORTWORX_SERVICE_PORT_9001_TCP=tcp://172.21.10.3:9001 PORTWORX_SERVICE_PORT_9001_TCP_ADDR=172.21.10.3 PORTWORX_SERVICE_PORT_9019_TCP=tcp://172.21.10.3:9019 PORTWORX_SERVICE_PORT_9019_TCP_ADDR=172.21.10.3 PORTWORX_SERVICE_PORT_9020_TCP=tcp://172.21.10.3:9020 PORTWORX_SERVICE_PORT_9020_TCP_ADDR=172.21.10.3 PORTWORX_SERVICE_PORT_9021_TCP=tcp://172.21.10.3:9021 PORTWORX_SERVICE_PORT_9021_TCP_ADDR=172.21.10.3 PORTWORX_SERVICE_SERVICE_HOST=172.21.10.3 STORK_SERVICE_PORT=tcp://172.21.135.114:8099 STORK_SERVICE_PORT_443_TCP=tcp://172.21.135.114:443 STORK_SERVICE_PORT_443_TCP_ADDR=172.21.135.114 STORK_SERVICE_PORT_8099_TCP=tcp://172.21.135.114:8099 STORK_SERVICE_PORT_8099_TCP_ADDR=172.21.135.114 STORK_SERVICE_SERVICE_HOST=172.21.135.114} rm{PORTWORX_API_PORT=tcp://172.21.247.204:9001 PORTWORX_API_PORT_9001_TCP=tcp://172.21.247.204:9001 PORTWORX_API_PORT_9001_TCP_ADDR=172.21.247.204 PORTWORX_API_PORT_9020_TCP=tcp://172.21.247.204:9020 PORTWORX_API_PORT_9020_TCP_ADDR=172.21.247.204 PORTWORX_API_PORT_9021_TCP=tcp://172.21.247.204:9021 PORTWORX_API_PORT_9021_TCP_ADDR=172.21.247.204 PORTWORX_API_SERVICE_HOST=172.21.247.204 PORTWORX_SERVICE_PORT=tcp://172.21.87.64:9001 PORTWORX_SERVICE_PORT_9001_TCP=tcp://172.21.87.64:9001 PORTWORX_SERVICE_PORT_9001_TCP_ADDR=172.21.87.64 PORTWORX_SERVICE_PORT_9019_TCP=tcp://172.21.87.64:9019 PORTWORX_SERVICE_PORT_9019_TCP_ADDR=172.21.87.64 PORTWORX_SERVICE_PORT_9020_TCP=tcp://172.21.87.64:9020 PORTWORX_SERVICE_PORT_9020_TCP_ADDR=172.21.87.64 PORTWORX_SERVICE_PORT_9021_TCP=tcp://172.21.87.64:9021 PORTWORX_SERVICE_PORT_9021_TCP_ADDR=172.21.87.64 PORTWORX_SERVICE_SERVICE_HOST=172.21.87.64 STORK_SERVICE_PORT=tcp://172.21.131.159:8099 STORK_SERVICE_PORT_443_TCP=tcp://172.21.131.159:443 STORK_SERVICE_PORT_443_TCP_ADDR=172.21.131.159 STORK_SERVICE_PORT_8099_TCP=tcp://172.21.131.159:8099 STORK_SERVICE_PORT_8099_TCP_ADDR=172.21.131.159 STORK_SERVICE_SERVICE_HOST=172.21.131.159}"
time="2020-11-18T06:26:51-06:00" level=info msg="PX-RunC arguments: -A -c pxlicencetest0002 -ca /etc/pwx/etcdcerts/ca.pem -f -k etcd:https://2c2187ee-ecbc-4138-be14-b51d6cbb6075.659dc287bad647f9b4fe17c4e4c38dcc.databases.appdomain.cloud:32216 -r 17001 -secret_type k8s -userpwd **********************************************:**************************************************************** -x kubernetes"
time="2020-11-18T06:26:51-06:00" level=info msg="PX-RunC mounts: /dev:/dev /etc/exports:/etc/exports /opt/pwx/oci/mounts/etc/hosts:/etc/hosts /etc/iscsi:/etc/iscsi /etc/mdadm:/etc/mdadm /etc/nvme:/etc/nvme /etc/nvmet:/etc/nvmet /etc/pwx:/etc/pwx /opt/pwx/oci/mounts/etc/pwx/etcdcerts:/etc/pwx/etcdcerts /etc/resolv.conf:/etc/resolv.conf:ro /etc/target:/etc/target /opt/pwx/bin:/export_bin /proc:/hostproc /lib/modules:/lib/modules proc:/proc:nosuid,noexec,nodev /run/docker:/run/docker /run/lock/iscsi:/run/lock/iscsi /run/log/journal:/run/log/journal:ro /run/lvm:/run/lvm /run/mdadm:/run/mdadm /run/udev:/run/udev sysfs:/sys:nosuid,noexec,nodev cgroup:/sys/fs/cgroup:nosuid,noexec,nodev /opt/pwx/oci/mounts/tmp/px-termination-log:/tmp/px-termination-log /usr/src:/usr/src /var/cores:/var/cores /var/data/kubelet:/var/data/kubelet:shared /run:/var/host_run:bind /var/lib/iscsi:/var/lib/iscsi /var/lib/nfs:/var/lib/nfs /var/lib/osd:/var/lib/osd:shared /var/lock/iscsi:/var/lock/iscsi /var/run/dbus:/var/run/dbus /opt/pwx/oci/mounts/var/run/secrets/kubernetes.io/serviceaccount:/var/run/secrets/kubernetes.io/serviceaccount"
time="2020-11-18T06:26:51-06:00" level=info msg="PX-RunC env: CONTAINER_RUNTIME=cri/cri-o ETCD_PASSWORD=**************************************************************** ETCD_USERNAME=ibm_cloud_19ed797f_cf97_417f_9d5d_4045d79358aa GOMAXPROCS=64 GOTRACEBACK=crash HOME=/root HOSTNAME=kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c KUBELET_DIR=/var/data/kubelet KUBERNETES_PORT=tcp://172.21.0.1:443 KUBERNETES_PORT_443_TCP=tcp://172.21.0.1:443 KUBERNETES_PORT_443_TCP_ADDR=172.21.0.1 KUBERNETES_PORT_443_TCP_PORT=443 KUBERNETES_PORT_443_TCP_PROTO=tcp KUBERNETES_SERVICE_HOST=172.21.0.1 KUBERNETES_SERVICE_PORT=443 KUBERNETES_SERVICE_PORT_HTTPS=443 LVM_USE_HOST=1 NFS_SERVICE=nfs-server.service PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin PORTWORX_API_PORT=tcp://172.21.41.113:9001 PORTWORX_API_PORT_9001_TCP=tcp://172.21.41.113:9001 PORTWORX_API_PORT_9001_TCP_ADDR=172.21.41.113 PORTWORX_API_PORT_9001_TCP_PORT=9001 PORTWORX_API_PORT_9001_TCP_PROTO=tcp PORTWORX_API_PORT_9020_TCP=tcp://172.21.41.113:9020 PORTWORX_API_PORT_9020_TCP_ADDR=172.21.41.113 PORTWORX_API_PORT_9020_TCP_PORT=9020 PORTWORX_API_PORT_9020_TCP_PROTO=tcp PORTWORX_API_PORT_9021_TCP=tcp://172.21.41.113:9021 PORTWORX_API_PORT_9021_TCP_ADDR=172.21.41.113 PORTWORX_API_PORT_9021_TCP_PORT=9021 PORTWORX_API_PORT_9021_TCP_PROTO=tcp PORTWORX_API_SERVICE_HOST=172.21.41.113 PORTWORX_API_SERVICE_PORT=9001 PORTWORX_API_SERVICE_PORT_PX_API=9001 PORTWORX_API_SERVICE_PORT_PX_REST_GATEWAY=9021 PORTWORX_API_SERVICE_PORT_PX_SDK=9020 PORTWORX_SERVICE_PORT=tcp://172.21.10.3:9001 PORTWORX_SERVICE_PORT_9001_TCP=tcp://172.21.10.3:9001 PORTWORX_SERVICE_PORT_9001_TCP_ADDR=172.21.10.3 PORTWORX_SERVICE_PORT_9001_TCP_PORT=9001 PORTWORX_SERVICE_PORT_9001_TCP_PROTO=tcp PORTWORX_SERVICE_PORT_9019_TCP=tcp://172.21.10.3:9019 PORTWORX_SERVICE_PORT_9019_TCP_ADDR=172.21.10.3 PORTWORX_SERVICE_PORT_9019_TCP_PORT=9019 PORTWORX_SERVICE_PORT_9019_TCP_PROTO=tcp PORTWORX_SERVICE_PORT_9020_TCP=tcp://172.21.10.3:9020 PORTWORX_SERVICE_PORT_9020_TCP_ADDR=172.21.10.3 PORTWORX_SERVICE_PORT_9020_TCP_PORT=9020 PORTWORX_SERVICE_PORT_9020_TCP_PROTO=tcp PORTWORX_SERVICE_PORT_9021_TCP=tcp://172.21.10.3:9021 PORTWORX_SERVICE_PORT_9021_TCP_ADDR=172.21.10.3 PORTWORX_SERVICE_PORT_9021_TCP_PORT=9021 PORTWORX_SERVICE_PORT_9021_TCP_PROTO=tcp PORTWORX_SERVICE_SERVICE_HOST=172.21.10.3 PORTWORX_SERVICE_SERVICE_PORT=9001 PORTWORX_SERVICE_SERVICE_PORT_PX_API=9001 PORTWORX_SERVICE_SERVICE_PORT_PX_KVDB=9019 PORTWORX_SERVICE_SERVICE_PORT_PX_REST_GATEWAY=9021 PORTWORX_SERVICE_SERVICE_PORT_PX_SDK=9020 PX_IMAGE=docker.io/portworx/px-enterprise:2.6.1 PX_IMAGE_DIGEST=sha256:25cbc0ec9db6794f350b3bed59e4eb9458bc49aac663fc608c4f48380daf88bd PX_LOGLEVEL=info PX_POD_IP=10.243.128.22 PX_RUNC=true PX_SHARED=/var/data/kubelet:shared:1;/var/lib/osd:shared:1 PX_TEMPLATE_VERSION=v2 PX_VERSION=2.6.1.0-fa99d8a STORK_SERVICE_PORT=tcp://172.21.135.114:8099 STORK_SERVICE_PORT_443_TCP=tcp://172.21.135.114:443 STORK_SERVICE_PORT_443_TCP_ADDR=172.21.135.114 STORK_SERVICE_PORT_443_TCP_PORT=443 STORK_SERVICE_PORT_443_TCP_PROTO=tcp STORK_SERVICE_PORT_8099_TCP=tcp://172.21.135.114:8099 STORK_SERVICE_PORT_8099_TCP_ADDR=172.21.135.114 STORK_SERVICE_PORT_8099_TCP_PORT=8099 STORK_SERVICE_PORT_8099_TCP_PROTO=tcp STORK_SERVICE_SERVICE_HOST=172.21.135.114 STORK_SERVICE_SERVICE_PORT=8099 STORK_SERVICE_SERVICE_PORT_EXTENDER=8099 STORK_SERVICE_SERVICE_PORT_WEBHOOK=443 TERM=xterm container=oci"
time="2020-11-18T06:26:51-06:00" level=info msg="/etc/systemd/system/portworx-reboot.service content unchanged [1dc97b965f3c6ad99aa3a92a02b2e8b1 /etc/systemd/system/portworx-reboot.service]"
time="2020-11-18T06:26:51-06:00" level=info msg="/etc/systemd/system/portworx.socket content unchanged [e80e04204b7a7d113db36c53f420d635 /etc/systemd/system/portworx.socket]"
time="2020-11-18T06:26:51-06:00" level=info msg="/etc/systemd/system/portworx-output.service content unchanged [7340d8be39a32f3b7d296ac8275bc2e1 /etc/systemd/system/portworx-output.service]"
time="2020-11-18T06:26:51-06:00" level=info msg="/etc/systemd/system/portworx.service content unchanged [4c6515ccf9c8cb3f81745795a981723c /etc/systemd/system/portworx.service]"
time="2020-11-18T12:26:51Z" level=info msg="runC spec got updated - restart pending"
time="2020-11-18T12:26:51Z" level=info msg="Portworx service restart required due to configuration update."
time="2020-11-18T12:26:51Z" level=warning msg="Reloading + Restarting portworx service"
time="2020-11-18T12:26:52Z" level=info msg="Service handler initialized via as DBus{type:dbus,svc:portworx-reboot.service,id:0xc000514d80}"
time="2020-11-18T12:26:52Z" level=info msg="Previous portworx.service started 219h49m59s ago"
time="2020-11-18T12:27:08Z" level=info msg="Activating node-watcher"
time="2020-11-18T12:27:08Z" level=info msg="Portworx service is ACTIVE"
time="2020-11-18T12:27:08Z" level=info msg="REST: Changing install-state: ST_INSTALL -> ST_FINISH"
time="2020-11-18T12:27:08Z" level=info msg="Start tailing portworx.service logs"
time="2020-11-18T12:27:09Z" level=info msg="> Starting local log-tailer"
time="2020-11-18T12:27:09Z" level=info msg="> run-local: /px-log-tail --follow -P @ -tf  -u portworx.service -u portworx-output.service -u init.scope -n 20000 -p 10715"
time="2020-11-18T12:27:09Z" level=info msg="Install done - MAIN exiting"
time="2020-11-18T12:27:09Z" level=info msg="-- Flushing logs for PID 10715 [20000 lines] --"
time="2020-11-18T12:27:09Z" level=info msg="-- Start tailing the logs for portworx.service, portworx-output.service, init.scope --"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: Setting portmap: 17001
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:09,699 CRIT Supervisor running as root (no user in config file)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:09,702 INFO supervisord started with pid 1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,705 INFO spawned: 'px-nfs' with pid 348
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,707 INFO spawned: 'relayd' with pid 349
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,709 INFO spawned: 'cron' with pid 350
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,712 INFO spawned: 'reboot-diags' with pid 351
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,715 INFO spawned: 'lttng' with pid 352
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c cron[11210]: (CRON) INFO (pidfile fd = 3)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,716 INFO spawned: 'exec' with pid 353
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c cron[11210]: (CRON) INFO (Skipping @reboot jobs -- not system startup)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,720 INFO spawned: 'cache_flush' with pid 361
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,723 INFO spawned: 'px-diag' with pid 362
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,725 INFO spawned: 'px-healthmon' with pid 363
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,732 INFO spawned: 'pxdaemon' with pid 365
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,741 INFO spawned: 'px-ns' with pid 378
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,746 INFO spawned: 'px_event_listener' with pid 384
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,759 INFO exited: px-nfs (exit status 0; expected)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,759 INFO exited: reboot-diags (exit status 0; expected)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:10,759 INFO exited: cache_flush (exit status 0; expected)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: Tracefile cleanup: Tracing disabled, remove all previous traces...
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: Clean out lttng tmpfs location: ...
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:10Z" level=info msg="px-ns Starting.."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:10Z" level=info msg="InitPxClient No authentication enabled"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: Installed NS trace handler for SIGHUP
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: Installed NS sig-handler for SIGUSR1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: Installed NS sig-handler for SIGUSR2
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: Starting NS server
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:11,803 INFO success: relayd entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:11,803 INFO success: cron entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:11,803 INFO success: lttng entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:11,803 INFO success: exec entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:11,803 INFO success: px-diag entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:11,803 INFO success: px-healthmon entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:11,803 INFO success: px-ns entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:11,803 INFO success: px_event_listener entered RUNNING state, process has stayed up for > than 1 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18 12:27:15,773 INFO success: pxdaemon entered RUNNING state, process has stayed up for > than 5 seconds (startsecs)
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: Tracing is disabled, not starting trace processes.
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: PXPROCS[INFO]: Started px-storage with pid 424
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: bash: connect: Connection refused
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: bash: /dev/tcp/localhost/17006: Connection refused
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: PXPROCS[INFO]: px-storage not started yet...sleeping
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: PXPROCS[INFO]: Started px with pid 435
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: PXPROCS[INFO]: Started watchdog with pid 436
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18_12:27:18: PX-Watchdog: Starting watcher
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18_12:27:18: PX-Watchdog: Waiting for px process to start
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020-11-18_12:27:18: PX-Watchdog: (pid 435): Begin monitoring
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:18Z" level=info msg="Registering [kernel] as a volume driver"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:18Z" level=info msg="Registered the Usage based Metering Agent...."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:18Z" level=info msg="Setting log level to info(4)"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:18Z" level=info msg="read config from env var" func=init package=boot
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:18Z" level=info msg="read config from config.json" func=init package=boot
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Alerts initialized successfully for this cluster"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Using external kvdb service."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Registered auditor for kvdb-response"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Registered auditor for kvdb-limits"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="created kv instance" func=initKv package=boot
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Setting lock timeout to: 3m0s"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="creating kvdb metrics wrapper"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="initialized external kvdb" func=init package=boot
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Node is initialized" func=setNodeInfo package=boot
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Using PX_POD_IP..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Detected Machine Hardware Type as: kvm (Virtual Machine)"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="initialized osdconfig manager" func=init package=boot
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="pushed config data to kvdb" func=InitAndBoot package=boot
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Starting PX Version: 2.6.1.0-fa99d8a - Build Version fa99d8ab152715429592e842b73a45f57223fb1d"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Using PX_POD_IP..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Found the following shared mountpoints: [/var/data/kubelet /var/lib/osd]"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Node a21a6a53-d40d-4106-bef6-2770ce43dc87 with Index (4) is Up"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:19Z" level=info msg="Initializing scheduler hook: kubernetes"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Configured PX Scheduler filter for kubernetes"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Configured PX Scheduler integration with Kubernetes"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="node previously initialized:true" func=main package=main
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX Configuration Loaded..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX Cluster ID: democluster-pw  (UUID: 4763924a-f89e-41c6-9c08-b2cf599a81d7)"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX Node ID: a21a6a53-d40d-4106-bef6-2770ce43dc87"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX Node Index: 4"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX Management Iface: "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX Discovery Server(s): [https://2c2187ee-ecbc-4138-be14-b51d6cbb6075.659dc287bad647f9b4fe17c4e4c38dcc.databases.appdomain.cloud:32216]"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX Storage Type:  Devices: [/dev/vdd], Raid Level: data() md()"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX Node Cache Function Attributes=CacheDevices: [], DedicatedCache: false"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Detected hardware type as: VirtualMachine"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Initializing licensing"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Local PX-Enterprise license in sync with global"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Licensing engine initialized successfully using ID 4763924a-f89e-41c6-9c08-b2cf599a81d7"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Found 14 features in ts-store license collection"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license AggregatedVolume{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license CloudMigration{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license EnablePlatformBare{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license EnablePlatformVM{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license EncryptedVolume{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license HaLevel{type=\"IBM Cloud\",count:3,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license Nodes{type=\"IBM Cloud\",count:1000,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license ResizeVolume{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license ScaledVolume{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license SharedVolume{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license SnapshotToObjectStore{type=\"IBM Cloud\",count:unlimited,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license Snapshots{type=\"IBM Cloud\",count:64,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license VolumeSize{type=\"IBM Cloud\",count:40,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Parsed license Volumes{type=\"IBM Cloud\",count:16384,ver:1.0,starts:2019-09-24 00:00:00,expires:2024-04-02 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License Volumes already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License VolumeSize already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License AggregatedVolume already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License SharedVolume already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License ScaledVolume already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License EncryptedVolume already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License ResizeVolume already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License SnapshotToObjectStore already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License CloudMigration already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License EnablePlatformVM already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License Snapshots already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="License HaLevel already included."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Adding default license NodeCapacity{type=\"default\",count:256,ver:1.0,starts:2020-11-18 12:27:20,expires:2024-04-03 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Adding default license NodeCapacityExtension{type=\"default\",count:256,ver:1.0,starts:2020-11-18 12:27:20,expires:2024-04-03 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Adding default license LocalVolumeAttaches{type=\"default\",count:256,ver:1.0,starts:2020-11-18 12:27:20,expires:2024-04-03 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Adding default license SnapshotToObjectStoreDaily{type=\"default\",count:unlimited,ver:1.0,starts:2020-11-18 12:27:20,expires:2024-04-03 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Adding default license OIDCSecurity{type=\"default\",count:unlimited,ver:1.0,starts:2020-11-18 12:27:20,expires:2024-04-03 23:59:59}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Global license watcher installed." startIdx=4454026
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX-Enterprise license configured successfully"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Attempting Secrets Login to Kubernetes Secrets endpoint..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX starting cluster manager..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX cluster manager running."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Adding cluster event listener: Scheduler"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Converting VolumeSpecs to SdkStoragePolicyObjects..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX starting storage..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Adding cluster event listener: PX Storage Service"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="px-dummy stopped listening..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="SDK TLS disabled" name=SDK-tcp
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="SDK-tcp gRPC Server ready on [::]:17017"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="SDK TLS disabled" name=SDK-unix
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="SDK-unix gRPC Server ready on /var/lib/osd/driver/pwx.sock"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="SDK gRPC REST Gateway started on port :17018"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Setting concurrent API limit: 20"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Starting server on port: :17001"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="PX API server running on port 17001."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Cluster manager starting..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Starting API Server with TLS Disabled."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="initializing osdconfig manager"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Starting Watchdog server."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Cluster state is OK... Joining the cluster."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Node a21a6a53-d40d-4106-bef6-2770ce43dc87 joining cluster..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Cluster ID: democluster-pw"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Node Mgmt IP: 10.243.128.22"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Node Data IP: 10.243.128.22"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Node HWType: VirtualMachine"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="This node does not participates in quorum decisions"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Updating proto driver with cluster domain info"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Cluster manager starting watch at version 4454036"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Waiting for the cluster to reach quorum..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Starting Gossip... Gossiping to these nodes : [10.243.64.46:17002 10.243.128.31:17002 10.243.64.42:17002 10.243.64.43:17002]"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:20Z" level=info msg="Authentication with Kubernetes Secrets succeeded!"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:21Z" level=info msg="gossip: Adding Node to gossip map: e23031e9-3c29-4e45-855f-1bfd772b446e"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:21Z" level=info msg="gossip: Adding Node to gossip map: 29ac783b-6d23-4dd9-960d-2bb8f32f06e0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:21Z" level=info msg="gossip: Adding Node to gossip map: 37c8f1de-ea4c-4b6d-b3e5-8c56f94f10ea"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:21Z" level=info msg="gossip: Adding Node to gossip map: 5618fe81-b031-4846-8367-9de37830a412"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:22Z" level=info msg="Found available drives [/dev/vdd] on the node. Transitioning into a storage node."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:22Z" level=warning msg="PX-CACHE: cache_blksize param() parsing failed Unit parse error: , ignored."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:25Z" level=info msg="[provider] IBM initialized"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:25Z" level=info msg="Authentication error Authentication error: Auth not supported for IBM cloud provider ibm, Geo {g2 eu-de eu-de-3 default default default default default default <nil>} "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:25Z" level=info msg="Made 1 pools"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:25Z" level=info msg="Benchmarking drive  /dev/vdd"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:27Z" level=warning msg="503   Node status not OK (STATUS_INIT)" Driver="Cluster API" ID=nodeHealth Request="Cluster API"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:30Z" level=info msg="gossip: Successfully joined with 2 node(s)"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="Storage pool WriteThroughput  13194000"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="Mounting metadata pool: Cos:LOW RaidLevel:\"raid0\" uuid:\"1163f7c9-4ef1-46f0-9b90-6fe8defc8ee9\" "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="HAL:Created volume:/var/.px/0/.reserve"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="Initializing journal: /var/.px/0/log"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="Mounting metadata pool: Cos:LOW RaidLevel:\"raid0\" uuid:\"1163f7c9-4ef1-46f0-9b90-6fe8defc8ee9\" "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="HAL:Created volume:/var/.px/0/.metadata"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="Applying labels to Pool 0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="Sync initinprogress,pxpool=0,mdpoolid=0,mdvol labels to Pool 0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:36Z" level=info msg="Created Metadata Volume: /var/.px/0/.metadata"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=warning msg="503   Node status not OK (STATUS_INIT)" Driver="Cluster API" ID=nodeHealth Request="Cluster API"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="nodeLabel[u]:4763924a-f89e-41c6-9c08-b2cf599a81d7"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="nodeLabel[i]:a21a6a53-d40d-4106-bef6-2770ce43dc87"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="nodeLabel[n]:4"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="Applying labels to Pool 0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="Sync pxpool=0,mdpoolid=0,mdvol,i=a21a6a53-d40d-4106-bef6-2770ce43dc87,n=4,u=4763924a-f89e-41c6-9c08-b2cf599a81d7 labels to Pool 0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="Starting collector watch on  at 0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="Watch cb for key pwx/democluster-pw/ returned err: done"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=error msg="Watch on key pwx/democluster-pw/ closed without a Cancel response."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=error msg="Watch for pwx/democluster-pw/ stopped"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="Cluster db snapshot at: 4454089"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:37Z" level=info msg="Not starting Docker Scheduler"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="Service Provider information..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tISP: SoftLayer"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tIP: 149.81.153.39"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tCountry: United States"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tCity: Chicago"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tZIP: 60666"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tRegion: IL"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tLat: 41.8781"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tLng: -87.6298"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="\tTimezone: America/Chicago"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="Starting storage provider with PXD"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info Error="<nil>" Function=nodeMap.Add MID=29ac783b-6d23-4dd9-960d-2bb8f32f06e0 NID=6 Status=Maintenance Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info Error="<nil>" Function=nodeMap.Add MID=37c8f1de-ea4c-4b6d-b3e5-8c56f94f10ea NID=1 Status=Maintenance Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info Error="<nil>" Function=nodeMap.Add MID=5618fe81-b031-4846-8367-9de37830a412 NID=2 Status=Down Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info Error="<nil>" Function=nodeMap.Add MID=a21a6a53-d40d-4106-bef6-2770ce43dc87 NID=4 Status= Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info Error="<nil>" Function=nodeMap.Add MID=e23031e9-3c29-4e45-855f-1bfd772b446e NID=0 Status=Maintenance Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="merged option: rpc_timeout_sec=120"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="merged option: execution_timeout_sec=60"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="merged option: stats_num_detach_volumes=1000"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg="rt-opts for cloudsnap-shmGuard set to:ON"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:38Z" level=info msg=Cloudsnap-ReInit
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="[provider] IBM initialized"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Authentication error Authentication error: Auth not supported for IBM cloud provider ibm, Geo {g2 eu-de eu-de-3 default default default default default default <nil>} "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Found 1 DataPools"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Loading datapool: Cos:LOW RaidLevel:\"raid0\" uuid:\"1163f7c9-4ef1-46f0-9b90-6fe8defc8ee9\" "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Applying labels to Pool 0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Waiting for storage to become available, node down version 4454094" Driver=pxd Function=NodeStart
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Initialized namespace mgr" Driver=pxd Function=loadVolumeMounts
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Loading block driver: Kernel Mode Driver"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=WARN msg="int SystemMonitor::load_smon_file(SystemMonitor::smon_err*): Failed to open sysmon file /var/.px/0/sysmond/sysmon: No such file or directory"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Setting up NS driver..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="NS driver setup done..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Waiting for px-daemon grpc server to start..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Starting px-daemon grpc server on :17005"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="px-daemon grpc server started"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="[Version: 4454089], [Identity: 4] [Control Device Id: 0]" Function=grpc-client.BlockInit Tag=4
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Setting rpc_timeout_sec option to 120"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Setting rpc_timeout_sec option to 120"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Using checksum: AD32"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Initializing thread pool with 8 total 8 cpu 8 io 8 high_cos 8 low_cos threads"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Number of locally attached volumes: 0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Processing shared memory bufpool.shm"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Finished processing shared memory"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Using driver version min: 7 max: 10"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Using checksummed log file: /var/.px/0/log"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Using checksum: CRHW for the log file"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="init: Using Log: /var/.px/0/log size: 134217728"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="merge_level: Recs: 0 0 0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Replaying the logs ..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Log::replay: empty log"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Using checksummed log file: /var/.px/0/log"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Using checksum: CRHW for the log file"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="GC deleted devices..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="DeviceStore GC: delete unreferenced subvolumes dir /var/.px/0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="DeviceStore GC: done"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Starting messenger ..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=WARN msg="zctx_new: Cannot set thread scheduler to SCHED_RR  1: Operation not permitted"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:27:41Z" level=INFO msg="Datastore ready."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg=Done Function=grpc-client.BlockInit Tag=4
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="BlockDriver Start done..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info Function=grpc-server.BlockReady Tag=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="[Done]" Function=grpc-server.BlockReady Tag=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:41Z" level=info msg="Storage is ready" Driver=pxd Error="node is not initialized with cluster domains" Function=NodeStart
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:47Z" level=warning msg="503   Node status not OK (STATUS_INIT)" Driver="Cluster API" ID=nodeHealth Request="Cluster API"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:27:57Z" level=warning msg="503   Node status not OK (STATUS_INIT)" Driver="Cluster API" ID=nodeHealth Request="Cluster API"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:07Z" level=warning msg="503   Node status not OK (STATUS_INIT)" Driver="Cluster API" ID=nodeHealth Request="Cluster API"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Scheduled background task *volume.assignCoordinatorOp at periodic 1m0s"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Scheduled background task *volume.licenseExpiryCheck at periodic 6h0m5s"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Scheduled background task *volume.volumeDetachAndSnapCleanupTask at periodic 10m0s"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Scheduled background task *volume.internalCoordinatorOperations at periodic 10m0s"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Selected this node 4 as the cluster coordinator - background tasks scheduled"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="resync-repl not enabled, not starting internal snapshots"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Setting up scheduled snapshots"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Schedule snapshots setup done"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Replaying watch updates from index 4454089, node up version: 4454150"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="collect: replaying 19 update(s) for 1 callback(s)"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Callback watchdog started"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Ignoring older node down update, version: 4454094, node up version: 4454150" Error="<nil>" Function=watchNodes MID=a21a6a53-d40d-4106-bef6-2770ce43dc87 NID=4 Status=Down Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Storage spec update" Error="<nil>" Function=watchNodes MID=37c8f1de-ea4c-4b6d-b3e5-8c56f94f10ea NID=1 Status=Maintenance Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Node 37c8f1de-ea4c-4b6d-b3e5-8c56f94f10ea" Driver=kernel Function=NodeStateChange Status=Maintenance
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="[NodeId: 1]" Function=grpc-client.NodeDown Tag=5
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="no-kvdb-support option change, enabled: true, kv-supported: true"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Node unavailable for provisioning : spec: {kernel 2.6.1.0-fa99d8a 0 TARGET_DS_TYPE_EXTERNAL_FS 1 1 37c8f1de-ea4c-4b6d-b3e5-8c56f94f10ea tcp://10.243.64.42:17003 http://10.243.64.42:17001 /var/.px /var/.px/0   {map[0:1:{1 /dev/vdd STORAGE_MEDIUM_MAGNETIC true 0 1.3193e+07 0 0 42949672960 4316442132 Unknown seconds:1605697817 nanos:949624520  false false {} [] 0}] Resources Scan OK 1  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  0 0 0 Up 42949672960 42949672960 0  {0 [] false 0 0 0 0 0 0 0 0    0 0 0}} {map[]  0  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  0 0 0  0 0 0  {0 [] false 0 0 0 0 0 0 0 0    0 0 0}} {g2 eu-de eu-de-2 default default default default default default <nil>}  map[ibm-cloud.kubernetes.io/sgx-enabled:false topology.kubernetes.io/region:eu-de beta.kubernetes.io/os:linux ibm-cloud.kubernetes.io/instance-id:02c7_d3811904-fc41-4b0f-b2f2-d3ef3806ddd2 ibm-cloud.kubernetes.io/iaas-provider:g2 ibm-cloud.kubernetes.io/worker-version:4.3.40_1544_openshift kubernetes.io/os:linux topology.kubernetes.io/zone:eu-de-2 ibm-cloud.kubernetes.io/worker-pool-id:buh2vl2f09o9u7r0s7m0-841b913 kubernetes.io/arch:amd64 ibm-cloud.kubernetes.io/worker-id:kube-buh2vl2f09o9u7r0s7m0-democluster-default-00000333 node.openshift.io/os_id:rhel failure-domain.beta.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/internal-ip:10.243.64.42 ibm-cloud.kubernetes.io/machine-type:mx2.16x128 ibm-cloud.kubernetes.io/subnet-id:02c7-25213c82-2154-4160-8614-4e5b247720dd ibm-cloud.kubernetes.io/worker-pool-name:default arch:amd64 beta.kubernetes.io/instance-type:mx2.16x128 kubernetes.io/hostname:10.243.64.42 node-role.kubernetes.io/master: node.kubernetes.io/instance-type:mx2.16x128 beta.kubernetes.io/arch:amd64 ibm-cloud.kubernetes.io/os:REDHAT_7_64 node-role.kubernetes.io/worker: failure-domain.beta.kubernetes.io/zone:eu-de-2 ibm-cloud.kubernetes.io/zone:eu-de-2] Maintenance 0 0 false [Cos:LOW RaidLevel:\"raid0\" labels:<key:\"arch\" value:\"amd64\" > labels:<key:\"beta.kubernetes.io/arch\" value:\"amd64\" > labels:<key:\"beta.kubernetes.io/instance-type\" value:\"mx2.16x128\" > labels:<key:\"beta.kubernetes.io/os\" value:\"linux\" > labels:<key:\"failure-domain.beta.kubernetes.io/region\" value:\"eu-de\" > labels:<key:\"failure-domain.beta.kubernetes.io/zone\" value:\"eu-de-2\" > labels:<key:\"ibm-cloud.kubernetes.io/iaas-provider\" value:\"g2\" > labels:<key:\"ibm-cloud.kubernetes.io/instance-id\" value:\"02c7_d3811904-fc41-4b0f-b2f2-d3ef3806ddd2\" > labels:<key:\"ibm-cloud.kubernetes.io/internal-ip\" value:\"10.243.64.42\" > labels:<key:\"ibm-cloud.kubernetes.io/machine-type\" value:\"mx2.16x128\" > labels:<key:\"ibm-cloud.kubernetes.io/os\" value:\"REDHAT_7_64\" > labels:<key:\"ibm-cloud.kubernetes.io/region\" value:\"eu-de\" > labels:<key:\"ibm-cloud.kubernetes.io/sgx-enabled\" value:\"false\" > labels:<key:\"ibm-cloud.kubernetes.io/subnet-id\" value:\"02c7-25213c82-2154-4160-8614-4e5b247720dd\" > labels:<key:\"ibm-cloud.kubernetes.io/worker-id\" value:\"kube-buh2vl2f09o9u7r0s7m0-democluster-default-00000333\" > labels:<key:\"ibm-cloud.kubernetes.io/worker-pool-id\" value:\"buh2vl2f09o9u7r0s7m0-841b913\" > labels:<key:\"ibm-cloud.kubernetes.io/worker-pool-name\" value:\"default\" > labels:<key:\"ibm-cloud.kubernetes.io/worker-version\" value:\"4.3.40_1544_openshift\" > labels:<key:\"ibm-cloud.kubernetes.io/zone\" value:\"eu-de-2\" > labels:<key:\"iopriority\" value:\"LOW\" > labels:<key:\"kubernetes.io/arch\" value:\"amd64\" > labels:<key:\"kubernetes.io/hostname\" value:\"10.243.64.42\" > labels:<key:\"kubernetes.io/os\" value:\"linux\" > labels:<key:\"medium\" value:\"STORAGE_MEDIUM_MAGNETIC\" > labels:<key:\"node-role.kubernetes.io/master\" value:\"\" > labels:<key:\"node-role.kubernetes.io/worker\" value:\"\" > labels:<key:\"node.kubernetes.io/instance-type\" value:\"mx2.16x128\" > labels:<key:\"node.openshift.io/os_id\" value:\"rhel\" > labels:<key:\"topology.kubernetes.io/region\" value:\"eu-de\" > labels:<key:\"topology.kubernetes.io/zone\" value:\"eu-de-2\" > uuid:\"88a59b1f-7ba5-484a-a959-da7cbd958518\" ] POOLTYPE_BTRFS 0   false 0 [] false  16 125736153088 0} current provision info: {37c8f1de-ea4c-4b6d-b3e5-8c56f94f10ea 1 false map[ibm-cloud.kubernetes.io/iaas-provider:g2 arch:amd64 ibm-cloud.kubernetes.io/worker-pool-name:default zones:eu-de-2 domain:default topology.kubernetes.io/zone:eu-de-2 node.openshift.io/os_id:rhel ibm-cloud.kubernetes.io/machine-type:mx2.16x128 ibm-cloud.kubernetes.io/instance-id:02c7_d3811904-fc41-4b0f-b2f2-d3ef3806ddd2 topology.kubernetes.io/region:eu-de kubernetes.io/arch:amd64 ibm-cloud.kubernetes.io/zone:eu-de-2 node-role.kubernetes.io/worker: ibm-cloud.kubernetes.io/sgx-enabled:false beta.kubernetes.io/arch:amd64 ibm-cloud.kubernetes.io/worker-version:4.3.40_1544_openshift failure-domain.beta.kubernetes.io/region:eu-de beta.kubernetes.io/instance-type:mx2.16x128 ibm-cloud.kubernetes.io/subnet-id:02c7-25213c82-2154-4160-8614-4e5b247720dd node.kubernetes.io/instance-type:mx2.16x128 racks:default failure-domain.beta.kubernetes.io/zone:eu-de-2 kubernetes.io/hostname:10.243.64.42 node-role.kubernetes.io/master: beta.kubernetes.io/os:linux regions:eu-de ibm-cloud.kubernetes.io/worker-pool-id:buh2vl2f09o9u7r0s7m0-841b913 kubernetes.io/os:linux ibm-cloud.kubernetes.io/internal-ip:10.243.64.42 ibm-cloud.kubernetes.io/os:REDHAT_7_64 ibm-cloud.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/worker-id:kube-buh2vl2f09o9u7r0s7m0-democluster-default-00000333] map[0:0xc4217f7bc0] 16 125736153088}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Storage spec update" Error="<nil>" Function=watchNodes MID=e23031e9-3c29-4e45-855f-1bfd772b446e NID=0 Status=Maintenance Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Node e23031e9-3c29-4e45-855f-1bfd772b446e" Driver=kernel Function=NodeStateChange Status=Maintenance
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="[NodeId: 0]" Function=grpc-client.NodeDown Tag=6
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Node unavailable for provisioning : spec: {kernel 2.6.1.0-fa99d8a 0 TARGET_DS_TYPE_EXTERNAL_FS 1 0 e23031e9-3c29-4e45-855f-1bfd772b446e tcp://10.243.64.46:17003 http://10.243.64.46:17001 /var/.px /var/.px/0   {map[0:1:{1 /dev/vdd STORAGE_MEDIUM_MAGNETIC true 0 1.3194e+07 0 0 42949672960 4316442132 Unknown seconds:1605698014 nanos:101772256  false false {} [] 0}] Resources Scan OK 1  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  0 0 0 Up 42949672960 42949672960 0  {0 [] false 0 0 0 0 0 0 0 0    0 0 0}} {map[]  0  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  0 0 0  0 0 0  {0 [] false 0 0 0 0 0 0 0 0    0 0 0}} {g2 eu-de eu-de-2 default default default default default default <nil>}  map[failure-domain.beta.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/sgx-enabled:false ibm-cloud.kubernetes.io/worker-pool-id:buh2vl2f09o9u7r0s7m0-841b913 ibm-cloud.kubernetes.io/zone:eu-de-2 arch:amd64 ibm-cloud.kubernetes.io/os:REDHAT_7_64 kubernetes.io/arch:amd64 kubernetes.io/os:linux kubernetes.io/hostname:10.243.64.46 node-role.kubernetes.io/worker: beta.kubernetes.io/arch:amd64 beta.kubernetes.io/instance-type:mx2.16x128 ibm-cloud.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/worker-pool-name:default ibm-cloud.kubernetes.io/instance-id:02c7_9a520385-eca1-4fa8-9daf-2a131d6f53a4 ibm-cloud.kubernetes.io/worker-id:kube-buh2vl2f09o9u7r0s7m0-democluster-default-000004a9 node.kubernetes.io/instance-type:mx2.16x128 topology.kubernetes.io/region:eu-de beta.kubernetes.io/os:linux ibm-cloud.kubernetes.io/iaas-provider:g2 ibm-cloud.kubernetes.io/internal-ip:10.243.64.46 ibm-cloud.kubernetes.io/subnet-id:02c7-25213c82-2154-4160-8614-4e5b247720dd node-role.kubernetes.io/master: topology.kubernetes.io/zone:eu-de-2 failure-domain.beta.kubernetes.io/zone:eu-de-2 ibm-cloud.kubernetes.io/machine-type:mx2.16x128 ibm-cloud.kubernetes.io/worker-version:4.3.40_1544_openshift node.openshift.io/os_id:rhel] Maintenance 0 0 false [Cos:LOW RaidLevel:\"raid0\" labels:<key:\"arch\" value:\"amd64\" > labels:<key:\"beta.kubernetes.io/arch\" value:\"amd64\" > labels:<key:\"beta.kubernetes.io/instance-type\" value:\"mx2.16x128\" > labels:<key:\"beta.kubernetes.io/os\" value:\"linux\" > labels:<key:\"failure-domain.beta.kubernetes.io/region\" value:\"eu-de\" > labels:<key:\"failure-domain.beta.kubernetes.io/zone\" value:\"eu-de-2\" > labels:<key:\"ibm-cloud.kubernetes.io/iaas-provider\" value:\"g2\" > labels:<key:\"ibm-cloud.kubernetes.io/instance-id\" value:\"02c7_9a520385-eca1-4fa8-9daf-2a131d6f53a4\" > labels:<key:\"ibm-cloud.kubernetes.io/internal-ip\" value:\"10.243.64.46\" > labels:<key:\"ibm-cloud.kubernetes.io/machine-type\" value:\"mx2.16x128\" > labels:<key:\"ibm-cloud.kubernetes.io/os\" value:\"REDHAT_7_64\" > labels:<key:\"ibm-cloud.kubernetes.io/region\" value:\"eu-de\" > labels:<key:\"ibm-cloud.kubernetes.io/sgx-enabled\" value:\"false\" > labels:<key:\"ibm-cloud.kubernetes.io/subnet-id\" value:\"02c7-25213c82-2154-4160-8614-4e5b247720dd\" > labels:<key:\"ibm-cloud.kubernetes.io/worker-id\" value:\"kube-buh2vl2f09o9u7r0s7m0-democluster-default-000004a9\" > labels:<key:\"ibm-cloud.kubernetes.io/worker-pool-id\" value:\"buh2vl2f09o9u7r0s7m0-841b913\" > labels:<key:\"ibm-cloud.kubernetes.io/worker-pool-name\" value:\"default\" > labels:<key:\"ibm-cloud.kubernetes.io/worker-version\" value:\"4.3.40_1544_openshift\" > labels:<key:\"ibm-cloud.kubernetes.io/zone\" value:\"eu-de-2\" > labels:<key:\"iopriority\" value:\"LOW\" > labels:<key:\"kubernetes.io/arch\" value:\"amd64\" > labels:<key:\"kubernetes.io/hostname\" value:\"10.243.64.46\" > labels:<key:\"kubernetes.io/os\" value:\"linux\" > labels:<key:\"medium\" value:\"STORAGE_MEDIUM_MAGNETIC\" > labels:<key:\"node-role.kubernetes.io/master\" value:\"\" > labels:<key:\"node-role.kubernetes.io/worker\" value:\"\" > labels:<key:\"node.kubernetes.io/instance-type\" value:\"mx2.16x128\" > labels:<key:\"node.openshift.io/os_id\" value:\"rhel\" > labels:<key:\"topology.kubernetes.io/region\" value:\"eu-de\" > labels:<key:\"topology.kubernetes.io/zone\" value:\"eu-de-2\" > uuid:\"28e21b73-f5ab-4e80-9865-930e85828e5c\" ] POOLTYPE_BTRFS 0   false 0 [] false  16 125736939520 0} current provision info: {e23031e9-3c29-4e45-855f-1bfd772b446e 0 false map[ibm-cloud.kubernetes.io/worker-id:kube-buh2vl2f09o9u7r0s7m0-democluster-default-000004a9 topology.kubernetes.io/zone:eu-de-2 ibm-cloud.kubernetes.io/sgx-enabled:false ibm-cloud.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/worker-version:4.3.40_1544_openshift racks:default ibm-cloud.kubernetes.io/worker-pool-id:buh2vl2f09o9u7r0s7m0-841b913 beta.kubernetes.io/arch:amd64 ibm-cloud.kubernetes.io/worker-pool-name:default failure-domain.beta.kubernetes.io/zone:eu-de-2 regions:eu-de kubernetes.io/os:linux kubernetes.io/hostname:10.243.64.46 domain:default node-role.kubernetes.io/master: ibm-cloud.kubernetes.io/machine-type:mx2.16x128 node.openshift.io/os_id:rhel node-role.kubernetes.io/worker: ibm-cloud.kubernetes.io/instance-id:02c7_9a520385-eca1-4fa8-9daf-2a131d6f53a4 node.kubernetes.io/instance-type:mx2.16x128 ibm-cloud.kubernetes.io/internal-ip:10.243.64.46 ibm-cloud.kubernetes.io/subnet-id:02c7-25213c82-2154-4160-8614-4e5b247720dd kubernetes.io/arch:amd64 beta.kubernetes.io/instance-type:mx2.16x128 ibm-cloud.kubernetes.io/iaas-provider:g2 failure-domain.beta.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/zone:eu-de-2 zones:eu-de-2 topology.kubernetes.io/region:eu-de beta.kubernetes.io/os:linux arch:amd64 ibm-cloud.kubernetes.io/os:REDHAT_7_64] map[0:0xc420d2cc00] 16 125736939520}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Storage spec update" Error="<nil>" Function=watchNodes MID=a21a6a53-d40d-4106-bef6-2770ce43dc87 NID=4 Status=Up Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Node a21a6a53-d40d-4106-bef6-2770ce43dc87" Driver=kernel Function=NodeStateChange Status=Up
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:28:08Z" level=INFO msg="Creating coordinator devices... "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:28:08Z" level=INFO msg="Replaying async writes ..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:28:08Z" level=INFO msg="Cleaning unwanted devices..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:28:08Z" level=NOTE msg="remove_unmounted: Done removing unwanted attached devices"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Scheduled cloudsnap cleanup task on this node"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Started task to monitor cloud migration restores on this node"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Started task to prune cloud migration statuses on this node"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Starting watch from index 4454152"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Reloading sharedv4 volumes: []"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Starting NFS services"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=warning msg="Using shared v4 feature nfs-server.service"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Initializing v4 export server"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Skipping duplicate 4454152 update"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Successfully started v4 export server"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Local v4 exports are Export list for localhost:\n"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Unmounting nfsd: umount: /proc/fs/nfsd: not mounted\n:exit status 32"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Successfully bound nfsd for exportfs "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Waiting for Namespace server..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="InitPxClient No authentication enabled"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Namespace server PID is 378"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=warning msg="Failed to read catalog mount point: open /tmp/catalog/: no such file or directory"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Cloudsnap threads set to 16"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Checking existing backup/restore operations..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Setting up cloud backup schedule..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Cloud backup schedules setup done"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Starting volume ha-reconcile background task"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="started no-kvdb gossip routine"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Starting metering agent..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Metering timer watcher installed."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:08Z" level=info msg="Metering license watcher installed."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="[provider] IBM initialized"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Authentication error Authentication error: Auth not supported for IBM cloud provider ibm, Geo {g2 eu-de eu-de-3 default default default default default default <nil>} "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="[metering] Returning agent for ibm"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Metering: getK8Secret: Read the data "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Metering: getK8Secret: Read the data "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Metering[ibm]: Detected license type as : PX-Enterprise IBM Cloud"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Detected license PX-Enterprise IBM"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Metering time 1h0m0s, Billing Timeout 72h0m0s, LicenseExpiry Timeout 168h0m0s"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="This node now participates in quorum decisions"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="migration is either ongoing or happened in recent past"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="alerts are not being migrated on this node:alerts migration ongoing or attempted in recent past"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Stopping updates collector"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Watch cb for key pwx/democluster-pw/ returned err: Stopped watch"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=error msg="Watch on key pwx/democluster-pw/ closed without a Cancel response."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=error msg="Watch for pwx/democluster-pw/ stopped"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Storage spec update" Error="<nil>" Function=watchNodes MID=a21a6a53-d40d-4106-bef6-2770ce43dc87 NID=4 Status=Up Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Node a21a6a53-d40d-4106-bef6-2770ce43dc87" Driver=kernel Function=NodeStateChange Status=Up
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="k8s node labels: map[beta.kubernetes.io/arch:amd64 ibm-cloud.kubernetes.io/instance-id:02d7_7919c219-bce5-4818-ba06-ef53353bb36a ibm-cloud.kubernetes.io/internal-ip:10.243.128.22 kubernetes.io/os:linux arch:amd64 ibm-cloud.kubernetes.io/iaas-provider:g2 ibm-cloud.kubernetes.io/subnet-id:02d7-72b8b499-26ba-4636-bb3f-2d18edc467bb node-role.kubernetes.io/worker: ibm-cloud.kubernetes.io/worker-pool-id:buh2vl2f09o9u7r0s7m0-0d944f2 ibm-cloud.kubernetes.io/worker-version:4.3.40_1544_openshift beta.kubernetes.io/instance-type:bx2.4x16 beta.kubernetes.io/os:linux node-role.kubernetes.io/master: node.openshift.io/os_id:rhel ibm-cloud.kubernetes.io/machine-type:bx2.4x16 node.kubernetes.io/instance-type:bx2.4x16 failure-domain.beta.kubernetes.io/region:eu-de failure-domain.beta.kubernetes.io/zone:eu-de-3 ibm-cloud.kubernetes.io/zone:eu-de-3 kubernetes.io/hostname:10.243.128.22 topology.kubernetes.io/zone:eu-de-3 topology.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/os:REDHAT_7_64 ibm-cloud.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/sgx-enabled:false ibm-cloud.kubernetes.io/worker-id:kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c ibm-cloud.kubernetes.io/worker-pool-name:newpool kubernetes.io/arch:amd64] differ from labels in cache: map[]. Updating storage pools."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="starting pool expansion watcher..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Starting REST service on socket : /run/docker/plugins/pxd.sock"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Starting REST service on socket : /var/lib/osd/driver/pxd.sock"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="PX is ready on Node: a21a6a53-d40d-4106-bef6-2770ce43dc87. CLI accessible at /opt/pwx/bin/pxctl."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Detected node 29ac783b-6d23-4dd9-960d-2bb8f32f06e0  to be in the cluster."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Detected node 37c8f1de-ea4c-4b6d-b3e5-8c56f94f10ea  to be in the cluster."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=warning msg="Detected new node with  5618fe81-b031-4846-8367-9de37830a412  to be offline due to inactivity."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="gossip: Request for a Node Leave operation on Node 5618fe81-b031-4846-8367-9de37830a412"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="gossip: Node 5618fe81-b031-4846-8367-9de37830a412 should go down."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Gossip indicated node 5618fe81-b031-4846-8367-9de37830a412 to go down. Original status update for 5618fe81-b031-4846-8367-9de37830a412" Driver=pxd Function=NodeUpdate
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=info msg="Detected node e23031e9-3c29-4e45-855f-1bfd772b446e  to be in the cluster."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=warning msg="Unable to list containers. Some containers using shared volumes may need to be restarted manually: Docker not yet initialized"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:11Z" level=warning msg="Unable to list containers. Some containers using shared volumes may need to be restarted manually: Docker not yet initialized"
time="2020-11-18T12:28:17Z" level=info msg="PX node status reports portworx service is healthy"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:28:42Z" level=info msg="Task to add k8s node watch is canceled"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:38:08Z" level=ERROR msg="Node 0 and pool 0 down for too long"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:38:08Z" level=ERROR msg="Node 1 and pool 0 down for too long"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:38:08Z" level=ERROR msg="Node 2 and pool 0 down for too long"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Background worker trying to decommission node 29ac783b-6d23-4dd9-960d-2bb8f32f06e0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="ClusterManager Remove node."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Remove node: ask cluster listener: can we remove node ID 29ac783b-6d23-4dd9-960d-2bb8f32f06e0, Scheduler"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Remove node: ask cluster listener: can we remove node ID 29ac783b-6d23-4dd9-960d-2bb8f32f06e0, PX Storage Service"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="ClusterManager watchDB, node ID 29ac783b-6d23-4dd9-960d-2bb8f32f06e0 state is Decommission."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="ClusterManager watchDB, decommsission node ID 29ac783b-6d23-4dd9-960d-2bb8f32f06e0 on this node"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="gossip: Removing node from gossip map: 29ac783b-6d23-4dd9-960d-2bb8f32f06e0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Remove node: notify cluster listener: Scheduler"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Remove node: notify cluster listener: PX Storage Service"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Storage Remove Node: 29ac783b-6d23-4dd9-960d-2bb8f32f06e0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Storage spec update" Error="<nil>" Function=watchNodes MID=29ac783b-6d23-4dd9-960d-2bb8f32f06e0 NID=6 Status=Maintenance Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Node 29ac783b-6d23-4dd9-960d-2bb8f32f06e0" Driver=kernel Function=NodeStateChange Status=Maintenance
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="[NodeId: 6]" Function=grpc-client.NodeDown Tag=856
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Node unavailable for provisioning : spec: {kernel 2.6.1.0-fa99d8a 0 TARGET_DS_TYPE_EXTERNAL_FS 1 6 29ac783b-6d23-4dd9-960d-2bb8f32f06e0 tcp://10.243.128.31:17003 http://10.243.128.31:17001 /var/.px /var/.px_md   {map[] Resources Scan OK 0  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  0 0 0 Up 0 0 0  {0 [] false 0 0 0 0 0 0 0 0    0 0 0}} {map[]  0  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  {  STORAGE_MEDIUM_MAGNETIC false 0 0 0 0 0 0  <nil> false false {} [] 0}  0 0 0  0 0 0  {0 [] false 0 0 0 0 0 0 0 0    0 0 0}} {g2 eu-de eu-de-3 default default default default default default <nil>}  map[beta.kubernetes.io/arch:amd64 topology.kubernetes.io/zone:eu-de-3 beta.kubernetes.io/instance-type:bx2.4x16 ibm-cloud.kubernetes.io/subnet-id:02d7-72b8b499-26ba-4636-bb3f-2d18edc467bb node-role.kubernetes.io/master: beta.kubernetes.io/os:linux failure-domain.beta.kubernetes.io/zone:eu-de-3 arch:amd64 ibm-cloud.kubernetes.io/sgx-enabled:false ibm-cloud.kubernetes.io/zone:eu-de-3 kubernetes.io/hostname:10.243.128.31 node.kubernetes.io/instance-type:bx2.4x16 ibm-cloud.kubernetes.io/instance-id:02d7_80d3ef9a-ef1c-4319-b293-7d23793b0c22 ibm-cloud.kubernetes.io/machine-type:bx2.4x16 ibm-cloud.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/worker-version:4.3.40_1545_openshift failure-domain.beta.kubernetes.io/region:eu-de kubernetes.io/arch:amd64 topology.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/worker-pool-name:newpool node-role.kubernetes.io/worker: ibm-cloud.kubernetes.io/worker-pool-id:buh2vl2f09o9u7r0s7m0-0d944f2 kubernetes.io/os:linux node.openshift.io/os_id:rhel ibm-cloud.kubernetes.io/iaas-provider:g2 ibm-cloud.kubernetes.io/internal-ip:10.243.128.31 ibm-cloud.kubernetes.io/os:REDHAT_7_64 ibm-cloud.kubernetes.io/worker-id:kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-000008f7] Maintenance 0 0 true [] POOLTYPE_BTRFS 0   false 0 [] false  4 15494733824 0} current provision info: {29ac783b-6d23-4dd9-960d-2bb8f32f06e0 6 false map[ibm-cloud.kubernetes.io/internal-ip:10.243.128.31 ibm-cloud.kubernetes.io/region:eu-de topology.kubernetes.io/region:eu-de node-role.kubernetes.io/worker: node.openshift.io/os_id:rhel beta.kubernetes.io/arch:amd64 node-role.kubernetes.io/master: failure-domain.beta.kubernetes.io/zone:eu-de-3 kubernetes.io/arch:amd64 ibm-cloud.kubernetes.io/worker-pool-name:newpool topology.kubernetes.io/zone:eu-de-3 arch:amd64 kubernetes.io/hostname:10.243.128.31 beta.kubernetes.io/instance-type:bx2.4x16 ibm-cloud.kubernetes.io/subnet-id:02d7-72b8b499-26ba-4636-bb3f-2d18edc467bb ibm-cloud.kubernetes.io/zone:eu-de-3 regions:eu-de zones:eu-de-3 racks:default domain:default ibm-cloud.kubernetes.io/instance-id:02d7_80d3ef9a-ef1c-4319-b293-7d23793b0c22 ibm-cloud.kubernetes.io/os:REDHAT_7_64 ibm-cloud.kubernetes.io/worker-pool-id:buh2vl2f09o9u7r0s7m0-0d944f2 kubernetes.io/os:linux beta.kubernetes.io/os:linux ibm-cloud.kubernetes.io/worker-version:4.3.40_1545_openshift failure-domain.beta.kubernetes.io/region:eu-de ibm-cloud.kubernetes.io/iaas-provider:g2 ibm-cloud.kubernetes.io/worker-id:kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-000008f7 ibm-cloud.kubernetes.io/sgx-enabled:false ibm-cloud.kubernetes.io/machine-type:bx2.4x16 node.kubernetes.io/instance-type:bx2.4x16] map[] 4 15494733824}"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Cluster manager node remove done: node ID 29ac783b-6d23-4dd9-960d-2bb8f32f06e0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=warning msg="Removing spec: 29ac783b-6d23-4dd9-960d-2bb8f32f06e0"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=warning msg="Node 29ac783b-6d23-4dd9-960d-2bb8f32f06e0 Removed" Action=8 Error="<nil>" Function=watchNodes Index=4455011 Key=storage/spec/29ac783b-6d23-4dd9-960d-2bb8f32f06e0 Value="[]uint8"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Delete Storage Spec" Error="<nil>" Function=watchNodes MID=29ac783b-6d23-4dd9-960d-2bb8f32f06e0 NID=6 Status=Maintenance Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=warning msg="BlockDriver NodeRemove: Handle notification Node Remove"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="[NodeId: 6]" Function=grpc-client.NodeRemove Tag=857
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18 12:48:23Z" level=INFO msg="block node_remove (version 4455011, node ID 6)"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=info msg="Node removed" Error="<nil>" Function=nodeMap.Remove MID=29ac783b-6d23-4dd9-960d-2bb8f32f06e0 NID=6 Status=Maintenance Version=1
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:23Z" level=warning msg="Attempt to decommission PX-Enterprise license ignored"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020/11/18 12:48:24 [WARN] memberlist 10.243.128.22: Suspect message from e23031e9-3c29-4e45-855f-1bfd772b446ev2
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: 2020/11/18 12:48:25 [INFO] memberlist deadNode 10.243.128.22 : dead : 29ac783b-6d23-4dd9-960d-2bb8f32f06e0v2
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T12:48:25Z" level=info msg="gossip: Could not update status on NotifyLeave : Node with id (29ac783b-6d23-4dd9-960d-2bb8f32f06e0) not found"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:12Z" level=info msg="Metering: Triggered data gathering"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:12Z" level=warning msg="Skipping node for billing 1 Maintenance"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:12Z" level=warning msg="Skipping node for billing 2 Down"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:12Z" level=warning msg="Skipping node for billing 0 Maintenance"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:12Z" level=info msg="Metering: (ibmcloud) Starting to send data..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:12Z" level=info msg="Metering: getK8Secret: Read the data "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: px-osb.osb-prod-1.us-east.containers.appdomain.cloud
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:12Z" level=info msg="Trying to dial px-osb.osb-prod-1.us-east.containers.appdomain.cloud:http, proxy: <nil>"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:14Z" level=info msg="sendUsage: response from the billing endpoint, status: 202"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:14Z" level=info msg="Metering: Data sent to the billing agent"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T13:28:14Z" level=info msg="Last reported time 2020-11-18 13:28:14.33627135 +0000 UTC m=+3655.534517108"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:15Z" level=info msg="Metering: Triggered data gathering"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:15Z" level=warning msg="Skipping node for billing 2 Down"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:15Z" level=warning msg="Skipping node for billing 0 Maintenance"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:15Z" level=warning msg="Skipping node for billing 1 Maintenance"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:15Z" level=info msg="Metering: (ibmcloud) Starting to send data..."
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:15Z" level=info msg="Metering: getK8Secret: Read the data "
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: px-osb.osb-prod-1.us-east.containers.appdomain.cloud
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:15Z" level=info msg="Trying to dial px-osb.osb-prod-1.us-east.containers.appdomain.cloud:http, proxy: <nil>"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:16Z" level=info msg="sendUsage: response from the billing endpoint, status: 202"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:16Z" level=info msg="Metering: Data sent to the billing agent"
@kube-buh2vl2f09o9u7r0s7m0-democluster-newpool-0000064c portworx[10706]: time="2020-11-18T14:28:16Z" level=info msg="Last reported time 2020-11-18 14:28:16.67644118 +0000 UTC m=+7257.874686936"
